{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.269471Z",
     "start_time": "2025-04-18T07:41:50.742473Z"
    }
   },
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.284476Z",
     "start_time": "2025-04-18T07:41:52.275471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        self._token_to_idx = token_to_idx if token_to_idx else {}\n",
    "        self._idx_to_token = {idx: token for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            return self._token_to_idx[token]\n",
    "        index = len(self._token_to_idx)\n",
    "        self._token_to_idx[token] = index\n",
    "        self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_many(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(f\"Index {index} not in vocabulary\")\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Vocabulary(size={len(self)})>\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "\n"
   ],
   "id": "ebdec067e85d2f0c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.509486Z",
     "start_time": "2025-04-18T07:41:52.495486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None, unk_token=\"<UNK>\", mask_token=\"<MASK>\",\n",
    "                 begin_seq_token=\"<BEGIN>\", end_seq_token=\"<END>\"):\n",
    "        super().__init__(token_to_idx)\n",
    "\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super().to_serializable()\n",
    "        contents.update({\n",
    "            'unk_token': self._unk_token,\n",
    "            'mask_token': self._mask_token,\n",
    "            'begin_seq_token': self._begin_seq_token,\n",
    "            'end_seq_token': self._end_seq_token\n",
    "        })\n",
    "        return contents\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        return self._token_to_idx.get(token, self.unk_index)\n",
    "\n"
   ],
   "id": "d604a974ace6ed9c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.539486Z",
     "start_time": "2025-04-18T07:41:52.525486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SurnameVectorizer:\n",
    "    def __init__(self, char_vocab, nationality_vocab):\n",
    "        self.char_vocab = char_vocab\n",
    "        self.nationality_vocab = nationality_vocab\n",
    "\n",
    "    def vectorize(self, surname, vector_length=-1):\n",
    "        indices = [self.char_vocab.begin_seq_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in surname)\n",
    "        indices.append(self.char_vocab.end_seq_index)\n",
    "\n",
    "        vector_length = len(indices) - 1 if vector_length < 0 else vector_length\n",
    "\n",
    "        from_vector = np.full(vector_length, self.char_vocab.mask_index, dtype=np.int64)\n",
    "        from_indices = indices[:-1]\n",
    "        from_vector[:len(from_indices)] = from_indices\n",
    "\n",
    "        to_vector = np.full(vector_length, self.char_vocab.mask_index, dtype=np.int64)\n",
    "        to_indices = indices[1:]\n",
    "        to_vector[:len(to_indices)] = to_indices\n",
    "\n",
    "        return from_vector, to_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, surname_df):\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        nationality_vocab = Vocabulary()\n",
    "\n",
    "        for _, row in surname_df.iterrows():\n",
    "            for char in row.surname:\n",
    "                char_vocab.add_token(char)\n",
    "            nationality_vocab.add_token(row.nationality)\n",
    "\n",
    "        return cls(char_vocab, nationality_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        char_vocab = SequenceVocabulary.from_serializable(contents['char_vocab'])\n",
    "        nat_vocab = Vocabulary.from_serializable(contents['nationality_vocab'])\n",
    "        return cls(char_vocab, nat_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\n",
    "            'char_vocab': self.char_vocab.to_serializable(),\n",
    "            'nationality_vocab': self.nationality_vocab.to_serializable()\n",
    "        }\n",
    "\n"
   ],
   "id": "e08af11ceafc1a7f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.569487Z",
     "start_time": "2025-04-18T07:41:52.555486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SurnameDataset(Dataset):\n",
    "    def __init__(self, surname_df, vectorizer):\n",
    "        self.surname_df = surname_df\n",
    "        self._vectorizer = vectorizer\n",
    "        self._max_seq_length = max(len(s) for s in surname_df.surname) + 2  # +2 for begin/end tokens\n",
    "\n",
    "        self._split_df = {\n",
    "            'train': surname_df[surname_df.split == 'train'],\n",
    "            'val': surname_df[surname_df.split == 'val'],\n",
    "            'test': surname_df[surname_df.split == 'test']\n",
    "        }\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        return cls(df, SurnameVectorizer.from_dataframe(df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, csv_path, vectorizer_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_path)\n",
    "        return cls(df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_path):\n",
    "        with open(vectorizer_path) as fp:\n",
    "            return SurnameVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self, vectorizer_path):\n",
    "        with open(vectorizer_path, 'w') as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split='train'):\n",
    "        self._target_split = split\n",
    "        self._target_df = self._split_df[split]\n",
    "        self._target_size = len(self._target_df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        from_vec, to_vec = self._vectorizer.vectorize(row.surname, self._max_seq_length)\n",
    "        nat_index = self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n",
    "        return {\n",
    "            'x_data': from_vec,\n",
    "            'y_target': to_vec,\n",
    "            'class_index': nat_index\n",
    "        }\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "\n"
   ],
   "id": "d2d03ee7262fd878",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.599498Z",
     "start_time": "2025-04-18T07:41:52.586486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    for batch in dataloader:\n",
    "        yield {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    if y_pred.dim() == 3:\n",
    "        y_pred = y_pred.view(-1, y_pred.size(2))\n",
    "    if y_true.dim() == 2:\n",
    "        y_true = y_true.view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    correct = (y_pred_indices == y_true).float()\n",
    "    valid = (y_true != mask_index).float()\n",
    "    return (correct * valid).sum().item() / valid.sum().item() * 100\n",
    "\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\n",
    "\n",
    "\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "\n"
   ],
   "id": "4ec944aff48b7c8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.629487Z",
     "start_time": "2025-04-18T07:41:52.615486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SurnameGenerationModel(nn.Module):\n",
    "    def __init__(self, char_embedding_size, char_vocab_size, rnn_hidden_size,\n",
    "                 batch_first=True, padding_idx=0, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(char_vocab_size, char_embedding_size, padding_idx=padding_idx)\n",
    "        self.rnn = nn.GRU(char_embedding_size, rnn_hidden_size, batch_first=batch_first)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, char_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        x_emb = self.emb(x_in)\n",
    "        rnn_out, _ = self.rnn(x_emb)\n",
    "        batch_size, seq_len, feat_size = rnn_out.shape\n",
    "\n",
    "        # Flatten for linear layer\n",
    "        rnn_out = rnn_out.contiguous().view(batch_size * seq_len, feat_size)\n",
    "        output = self.fc(self.dropout(rnn_out))\n",
    "\n",
    "        if apply_softmax:\n",
    "            output = F.softmax(output, dim=1)\n",
    "\n",
    "        return output.view(batch_size, seq_len, -1)\n",
    "\n"
   ],
   "id": "4297a380dd6b13c5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.659495Z",
     "start_time": "2025-04-18T07:41:52.645487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_from_model(model, vectorizer, num_samples=1, sample_size=20, temperature=1.0):\n",
    "    begin_idx = [[vectorizer.char_vocab.begin_seq_index]] * num_samples\n",
    "    begin_tensor = torch.tensor(begin_idx, dtype=torch.int64)\n",
    "    sequences = [begin_tensor]\n",
    "    h_t = None\n",
    "\n",
    "    for _ in range(sample_size):\n",
    "        x_t = sequences[-1]\n",
    "        emb_t = model.emb(x_t)\n",
    "        rnn_out, h_t = model.rnn(emb_t, h_t)\n",
    "        logits = model.fc(rnn_out.squeeze(1))\n",
    "        probs = F.softmax(logits / temperature, dim=1)\n",
    "        next_tokens = torch.multinomial(probs, num_samples=1)\n",
    "        sequences.append(next_tokens)\n",
    "\n",
    "    return torch.cat(sequences, dim=1)\n",
    "\n",
    "\n",
    "def decode_samples(sampled_indices, vectorizer):\n",
    "    vocab = vectorizer.char_vocab\n",
    "    decoded = []\n",
    "    for sample in sampled_indices:\n",
    "        chars = []\n",
    "        for idx in sample[1:]:  # Skip begin token\n",
    "            if idx.item() == vocab.end_seq_index:\n",
    "                break\n",
    "            chars.append(vocab.lookup_index(idx.item()))\n",
    "        decoded.append(''.join(chars))\n",
    "    return decoded\n",
    "\n"
   ],
   "id": "373e5e721b3afde5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.689496Z",
     "start_time": "2025-04-18T07:41:52.675487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_train_state(args):\n",
    "    return {\n",
    "        'stop_early': False,\n",
    "        'early_stopping_step': 0,\n",
    "        'early_stopping_best_val': float('inf'),\n",
    "        'epoch_index': 0,\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'test_loss': -1,\n",
    "        'test_acc': -1,\n",
    "        'model_filename': args.model_state_file\n",
    "    }\n",
    "\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "    else:\n",
    "        current_loss = train_state['val_loss'][-1]\n",
    "        if current_loss < train_state['early_stopping_best_val']:\n",
    "            torch.save(model.state_dict(), train_state['model_filename'])\n",
    "            train_state['early_stopping_best_val'] = current_loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1\n",
    "            if train_state['early_stopping_step'] >= args.early_stopping_criteria:\n",
    "                train_state['stop_early'] = True\n",
    "    return train_state\n",
    "\n"
   ],
   "id": "b5ac0b5fa21421ac",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:52.719495Z",
     "start_time": "2025-04-18T07:41:52.705487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args = Namespace(\n",
    "    surname_csv=\"surnames_with_splits.csv\",\n",
    "    vectorizer_file=\"vectorizer.json\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage/char_rnn\",\n",
    "    char_embedding_size=64,\n",
    "    rnn_hidden_size=64,\n",
    "    batch_size=128,\n",
    "    num_epochs=100,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=1e-3,\n",
    "    seed=42,\n",
    "    cuda=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    reload_from_files=False\n",
    ")\n",
    "\n",
    "# 路径处理\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "# 设备设置\n",
    "device = torch.device(\"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\")\n"
   ],
   "id": "268ee1e01191e794",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:41:53.034486Z",
     "start_time": "2025-04-18T07:41:52.735486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "handle_dirs(args.save_dir)\n",
    "\n",
    "# 数据加载\n",
    "if args.reload_from_files:\n",
    "    dataset = SurnameDataset.load_dataset_and_load_vectorizer(args.surname_csv, args.vectorizer_file)\n",
    "else:\n",
    "    dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "# 模型初始化\n",
    "model = SurnameGenerationModel(\n",
    "    char_embedding_size=args.char_embedding_size,\n",
    "    char_vocab_size=len(vectorizer.char_vocab),\n",
    "    rnn_hidden_size=args.rnn_hidden_size,\n",
    "    padding_idx=mask_index\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "train_state = make_train_state(args)\n"
   ],
   "id": "1a968ecdc0e70521",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:45:12.851049Z",
     "start_time": "2025-04-18T07:41:53.051486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, args.batch_size, device=device)\n",
    "        progress_bar = tqdm(batch_generator,\n",
    "                            total=dataset.get_num_batches(args.batch_size),\n",
    "                            desc=f\"Epoch {epoch} Train\")\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(batch['x_data'])\n",
    "            loss = sequence_loss(y_pred, batch['y_target'], mask_index)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = compute_accuracy(y_pred, batch['y_target'], mask_index)\n",
    "            running_loss = (running_loss * batch_idx + loss.item()) / (batch_idx + 1)\n",
    "            running_acc = (running_acc * batch_idx + acc) / (batch_idx + 1)\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{running_loss:.4f}\",\n",
    "                'acc': f\"{running_acc:.2f}%\"\n",
    "            })\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, args.batch_size, device=device)\n",
    "        progress_bar = tqdm(batch_generator,\n",
    "                            total=dataset.get_num_batches(args.batch_size),\n",
    "                            desc=f\"Epoch {epoch} Val\")\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(progress_bar):\n",
    "                y_pred = model(batch['x_data'])\n",
    "                loss = sequence_loss(y_pred, batch['y_target'], mask_index)\n",
    "                acc = compute_accuracy(y_pred, batch['y_target'], mask_index)\n",
    "\n",
    "                val_loss = (val_loss * batch_idx + loss.item()) / (batch_idx + 1)\n",
    "                val_acc = (val_acc * batch_idx + acc) / (batch_idx + 1)\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    'val_loss': f\"{val_loss:.4f}\",\n",
    "                    'val_acc': f\"{val_acc:.2f}%\"\n",
    "                })\n",
    "\n",
    "        train_state['val_loss'].append(val_loss)\n",
    "        train_state['val_acc'].append(val_acc)\n",
    "\n",
    "        # Update state\n",
    "        train_state = update_train_state(args, model, train_state)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        # Sampling demonstration\n",
    "        model.cpu()\n",
    "        samples = decode_samples(\n",
    "            sample_from_model(model, vectorizer, num_samples=2, temperature=0.6),\n",
    "            vectorizer\n",
    "        )\n",
    "        print(f\"\\nSamples after epoch {epoch}:\")\n",
    "        print(\"\\n\".join(samples))\n",
    "        model.to(device)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted\")\n"
   ],
   "id": "da8d78b0f0d11707",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train: 100%|██████████| 60/60 [00:02<00:00, 28.45it/s, loss=3.6147, acc=13.17%]\n",
      "Epoch 0 Val: 100%|██████████| 12/12 [00:00<00:00, 57.97it/s, val_loss=2.9292, val_acc=19.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 0:\n",
      "Jauno\n",
      "Tagirero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|██████████| 60/60 [00:01<00:00, 33.65it/s, loss=2.8713, acc=20.66%]\n",
      "Epoch 1 Val: 100%|██████████| 12/12 [00:00<00:00, 58.25it/s, val_loss=2.6661, val_acc=24.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 1:\n",
      "Manchula\n",
      "Bero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: 100%|██████████| 60/60 [00:01<00:00, 33.48it/s, loss=2.7059, acc=22.43%]\n",
      "Epoch 2 Val: 100%|██████████| 12/12 [00:00<00:00, 56.87it/s, val_loss=2.5750, val_acc=24.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 2:\n",
      "Aner\n",
      "Modir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: 100%|██████████| 60/60 [00:01<00:00, 31.91it/s, loss=2.6386, acc=23.47%]\n",
      "Epoch 3 Val: 100%|██████████| 12/12 [00:00<00:00, 49.79it/s, val_loss=2.5340, val_acc=25.37%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 3:\n",
      "Perocon\n",
      "Muaand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train: 100%|██████████| 60/60 [00:01<00:00, 34.15it/s, loss=2.5969, acc=24.12%]\n",
      "Epoch 4 Val: 100%|██████████| 12/12 [00:00<00:00, 59.12it/s, val_loss=2.5073, val_acc=25.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 4:\n",
      "Caastin\n",
      "Ohurdon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train: 100%|██████████| 60/60 [00:01<00:00, 34.34it/s, loss=2.5694, acc=24.45%]\n",
      "Epoch 5 Val: 100%|██████████| 12/12 [00:00<00:00, 58.53it/s, val_loss=2.4818, val_acc=26.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 5:\n",
      "Cadu\n",
      "Dalher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train: 100%|██████████| 60/60 [00:01<00:00, 34.23it/s, loss=2.5492, acc=24.68%]\n",
      "Epoch 6 Val: 100%|██████████| 12/12 [00:00<00:00, 60.30it/s, val_loss=2.4642, val_acc=26.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 6:\n",
      "Vanebima\n",
      "Hour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train: 100%|██████████| 60/60 [00:01<00:00, 34.35it/s, loss=2.5332, acc=24.97%]\n",
      "Epoch 7 Val: 100%|██████████| 12/12 [00:00<00:00, 57.97it/s, val_loss=2.4507, val_acc=26.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 7:\n",
      "Mannov\n",
      "Wimatain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train: 100%|██████████| 60/60 [00:01<00:00, 34.44it/s, loss=2.5212, acc=25.24%]\n",
      "Epoch 8 Val: 100%|██████████| 12/12 [00:00<00:00, 58.54it/s, val_loss=2.4331, val_acc=26.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 8:\n",
      "Tushmay\n",
      "Kitser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train: 100%|██████████| 60/60 [00:01<00:00, 35.15it/s, loss=2.5053, acc=25.63%]\n",
      "Epoch 9 Val: 100%|██████████| 12/12 [00:00<00:00, 58.82it/s, val_loss=2.4274, val_acc=27.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 9:\n",
      "Odyak\n",
      "Sam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: 100%|██████████| 60/60 [00:01<00:00, 34.17it/s, loss=2.4938, acc=26.05%]\n",
      "Epoch 10 Val: 100%|██████████| 12/12 [00:00<00:00, 57.69it/s, val_loss=2.4144, val_acc=27.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 10:\n",
      "Sarata\n",
      "Dakerro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: 100%|██████████| 60/60 [00:01<00:00, 33.28it/s, loss=2.4827, acc=26.25%]\n",
      "Epoch 11 Val: 100%|██████████| 12/12 [00:00<00:00, 59.41it/s, val_loss=2.4038, val_acc=28.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 11:\n",
      "Tomthi\n",
      "Kroste\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: 100%|██████████| 60/60 [00:01<00:00, 34.68it/s, loss=2.4755, acc=26.52%]\n",
      "Epoch 12 Val: 100%|██████████| 12/12 [00:00<00:00, 59.70it/s, val_loss=2.3933, val_acc=27.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 12:\n",
      "Turna\n",
      "Arasan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: 100%|██████████| 60/60 [00:05<00:00, 11.37it/s, loss=2.4637, acc=26.62%]\n",
      "Epoch 13 Val: 100%|██████████| 12/12 [00:00<00:00, 29.85it/s, val_loss=2.3889, val_acc=27.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 13:\n",
      "Songan\n",
      "Esend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: 100%|██████████| 60/60 [00:04<00:00, 12.45it/s, loss=2.4579, acc=26.81%]\n",
      "Epoch 14 Val: 100%|██████████| 12/12 [00:00<00:00, 30.30it/s, val_loss=2.3756, val_acc=28.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 14:\n",
      "Handal\n",
      "Romak\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train: 100%|██████████| 60/60 [00:04<00:00, 13.66it/s, loss=2.4507, acc=27.15%]\n",
      "Epoch 15 Val: 100%|██████████| 12/12 [00:00<00:00, 28.50it/s, val_loss=2.3702, val_acc=28.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 15:\n",
      "Esner\n",
      "Shaman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train: 100%|██████████| 60/60 [00:05<00:00, 11.75it/s, loss=2.4414, acc=27.30%]\n",
      "Epoch 16 Val: 100%|██████████| 12/12 [00:00<00:00, 30.30it/s, val_loss=2.3680, val_acc=28.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 16:\n",
      "Nawan\n",
      "Makson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train: 100%|██████████| 60/60 [00:02<00:00, 25.01it/s, loss=2.4360, acc=27.49%]\n",
      "Epoch 17 Val: 100%|██████████| 12/12 [00:00<00:00, 56.60it/s, val_loss=2.3573, val_acc=29.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 17:\n",
      "Naim\n",
      "Awlan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train: 100%|██████████| 60/60 [00:01<00:00, 34.13it/s, loss=2.4267, acc=27.67%]\n",
      "Epoch 18 Val: 100%|██████████| 12/12 [00:00<00:00, 57.98it/s, val_loss=2.3551, val_acc=29.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 18:\n",
      "Rougon\n",
      "Pamer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train: 100%|██████████| 60/60 [00:01<00:00, 34.17it/s, loss=2.4200, acc=27.81%]\n",
      "Epoch 19 Val: 100%|██████████| 12/12 [00:00<00:00, 56.87it/s, val_loss=2.3464, val_acc=29.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 19:\n",
      "Ronge\n",
      "Versell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train: 100%|██████████| 60/60 [00:01<00:00, 33.82it/s, loss=2.4137, acc=27.95%]\n",
      "Epoch 20 Val: 100%|██████████| 12/12 [00:00<00:00, 55.81it/s, val_loss=2.3435, val_acc=29.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 20:\n",
      "Lear\n",
      "Zhuraja\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train: 100%|██████████| 60/60 [00:01<00:00, 34.09it/s, loss=2.4144, acc=28.03%]\n",
      "Epoch 21 Val: 100%|██████████| 12/12 [00:00<00:00, 55.28it/s, val_loss=2.3435, val_acc=30.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 21:\n",
      "Coroan\n",
      "Naelbas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train: 100%|██████████| 60/60 [00:01<00:00, 34.42it/s, loss=2.4093, acc=28.13%]\n",
      "Epoch 22 Val: 100%|██████████| 12/12 [00:00<00:00, 59.11it/s, val_loss=2.3358, val_acc=29.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 22:\n",
      "Heladov\n",
      "Kersin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train: 100%|██████████| 60/60 [00:01<00:00, 34.60it/s, loss=2.4008, acc=28.30%]\n",
      "Epoch 23 Val: 100%|██████████| 12/12 [00:00<00:00, 55.55it/s, val_loss=2.3293, val_acc=30.23%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 23:\n",
      "Kinner\n",
      "Makashin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train: 100%|██████████| 60/60 [00:01<00:00, 34.14it/s, loss=2.4009, acc=28.61%]\n",
      "Epoch 24 Val: 100%|██████████| 12/12 [00:00<00:00, 59.11it/s, val_loss=2.3238, val_acc=30.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 24:\n",
      "Makaa\n",
      "Pullon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train: 100%|██████████| 60/60 [00:01<00:00, 34.70it/s, loss=2.3927, acc=28.65%]\n",
      "Epoch 25 Val: 100%|██████████| 12/12 [00:00<00:00, 57.97it/s, val_loss=2.3195, val_acc=30.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 25:\n",
      "Malanov\n",
      "Shajer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train: 100%|██████████| 60/60 [00:01<00:00, 34.38it/s, loss=2.3907, acc=28.79%]\n",
      "Epoch 26 Val: 100%|██████████| 12/12 [00:00<00:00, 58.24it/s, val_loss=2.3193, val_acc=30.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 26:\n",
      "Bazer\n",
      "Tanel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train: 100%|██████████| 60/60 [00:01<00:00, 33.80it/s, loss=2.3855, acc=28.98%]\n",
      "Epoch 27 Val: 100%|██████████| 12/12 [00:00<00:00, 50.65it/s, val_loss=2.3121, val_acc=30.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 27:\n",
      "Salbon\n",
      "Saren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train: 100%|██████████| 60/60 [00:01<00:00, 32.77it/s, loss=2.3824, acc=29.04%]\n",
      "Epoch 28 Val: 100%|██████████| 12/12 [00:00<00:00, 56.07it/s, val_loss=2.3087, val_acc=30.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 28:\n",
      "In\n",
      "Wetts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train: 100%|██████████| 60/60 [00:01<00:00, 33.11it/s, loss=2.3763, acc=29.33%]\n",
      "Epoch 29 Val: 100%|██████████| 12/12 [00:00<00:00, 58.54it/s, val_loss=2.3061, val_acc=30.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 29:\n",
      "Batati\n",
      "Kacsen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train: 100%|██████████| 60/60 [00:01<00:00, 33.52it/s, loss=2.3728, acc=29.25%]\n",
      "Epoch 30 Val: 100%|██████████| 12/12 [00:00<00:00, 56.35it/s, val_loss=2.3023, val_acc=30.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 30:\n",
      "Males\n",
      "Samouk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Train: 100%|██████████| 60/60 [00:01<00:00, 33.90it/s, loss=2.3693, acc=29.47%]\n",
      "Epoch 31 Val: 100%|██████████| 12/12 [00:00<00:00, 58.25it/s, val_loss=2.3015, val_acc=31.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 31:\n",
      "Blong\n",
      "Loun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Train: 100%|██████████| 60/60 [00:01<00:00, 33.56it/s, loss=2.3673, acc=29.42%]\n",
      "Epoch 32 Val: 100%|██████████| 12/12 [00:00<00:00, 53.79it/s, val_loss=2.3025, val_acc=30.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 32:\n",
      "Tomanan\n",
      "Awshan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Train: 100%|██████████| 60/60 [00:01<00:00, 33.82it/s, loss=2.3615, acc=29.80%]\n",
      "Epoch 33 Val: 100%|██████████| 12/12 [00:00<00:00, 56.60it/s, val_loss=2.2944, val_acc=31.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 33:\n",
      "Baba\n",
      "Konori\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Train: 100%|██████████| 60/60 [00:01<00:00, 33.37it/s, loss=2.3554, acc=29.69%]\n",
      "Epoch 34 Val: 100%|██████████| 12/12 [00:00<00:00, 57.14it/s, val_loss=2.2940, val_acc=31.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 34:\n",
      "Salmi\n",
      "Marlei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Train: 100%|██████████| 60/60 [00:01<00:00, 34.19it/s, loss=2.3560, acc=29.78%]\n",
      "Epoch 35 Val: 100%|██████████| 12/12 [00:00<00:00, 56.05it/s, val_loss=2.2916, val_acc=31.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 35:\n",
      "Adicher\n",
      "Karimin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Train: 100%|██████████| 60/60 [00:02<00:00, 26.43it/s, loss=2.3504, acc=29.64%]\n",
      "Epoch 36 Val: 100%|██████████| 12/12 [00:00<00:00, 28.98it/s, val_loss=2.2902, val_acc=31.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 36:\n",
      "Harlon\n",
      "Shelmov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Train: 100%|██████████| 60/60 [00:04<00:00, 14.28it/s, loss=2.3470, acc=29.96%]\n",
      "Epoch 37 Val: 100%|██████████| 12/12 [00:00<00:00, 31.58it/s, val_loss=2.2853, val_acc=31.74%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 37:\n",
      "Vanter\n",
      "Buher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Train: 100%|██████████| 60/60 [00:04<00:00, 12.78it/s, loss=2.3454, acc=30.15%]\n",
      "Epoch 38 Val: 100%|██████████| 12/12 [00:00<00:00, 28.85it/s, val_loss=2.2786, val_acc=31.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 38:\n",
      "Dary\n",
      "Scherer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Train: 100%|██████████| 60/60 [00:05<00:00, 11.69it/s, loss=2.3426, acc=30.08%]\n",
      "Epoch 39 Val: 100%|██████████| 12/12 [00:00<00:00, 29.17it/s, val_loss=2.2842, val_acc=31.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 39:\n",
      "Matis\n",
      "Kiletsan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Train: 100%|██████████| 60/60 [00:04<00:00, 12.16it/s, loss=2.3361, acc=30.37%]\n",
      "Epoch 40 Val: 100%|██████████| 12/12 [00:00<00:00, 29.56it/s, val_loss=2.2789, val_acc=31.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 40:\n",
      "Sarer\n",
      "Iva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Train: 100%|██████████| 60/60 [00:04<00:00, 12.21it/s, loss=2.3359, acc=30.34%]\n",
      "Epoch 41 Val: 100%|██████████| 12/12 [00:00<00:00, 31.50it/s, val_loss=2.2773, val_acc=32.02%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 41:\n",
      "Abblonb\n",
      "Deens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Train: 100%|██████████| 60/60 [00:04<00:00, 13.76it/s, loss=2.3318, acc=30.46%]\n",
      "Epoch 42 Val: 100%|██████████| 12/12 [00:00<00:00, 30.69it/s, val_loss=2.2732, val_acc=31.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 42:\n",
      "Makour\n",
      "Bang\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Train: 100%|██████████| 60/60 [00:04<00:00, 14.14it/s, loss=2.3296, acc=30.42%]\n",
      "Epoch 43 Val: 100%|██████████| 12/12 [00:00<00:00, 28.84it/s, val_loss=2.2712, val_acc=32.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 43:\n",
      "Essa\n",
      "Fertan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Train: 100%|██████████| 60/60 [00:04<00:00, 14.20it/s, loss=2.3299, acc=30.63%]\n",
      "Epoch 44 Val: 100%|██████████| 12/12 [00:00<00:00, 29.56it/s, val_loss=2.2736, val_acc=32.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 44:\n",
      "Vadas\n",
      "Zhelman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Train: 100%|██████████| 60/60 [00:04<00:00, 14.81it/s, loss=2.3237, acc=30.69%]\n",
      "Epoch 45 Val: 100%|██████████| 12/12 [00:00<00:00, 56.60it/s, val_loss=2.2709, val_acc=32.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 45:\n",
      "Berrin\n",
      "Wai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Train: 100%|██████████| 60/60 [00:01<00:00, 33.63it/s, loss=2.3217, acc=30.62%]\n",
      "Epoch 46 Val: 100%|██████████| 12/12 [00:00<00:00, 57.70it/s, val_loss=2.2667, val_acc=32.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 46:\n",
      "Shaima\n",
      "Kabelani\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Train: 100%|██████████| 60/60 [00:01<00:00, 33.94it/s, loss=2.3174, acc=30.92%]\n",
      "Epoch 47 Val: 100%|██████████| 12/12 [00:00<00:00, 57.98it/s, val_loss=2.2650, val_acc=32.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 47:\n",
      "Gillin\n",
      "Nakalon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Train: 100%|██████████| 60/60 [00:01<00:00, 34.28it/s, loss=2.3156, acc=30.83%]\n",
      "Epoch 48 Val: 100%|██████████| 12/12 [00:00<00:00, 58.25it/s, val_loss=2.2646, val_acc=32.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 48:\n",
      "Baraka\n",
      "Mata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Train: 100%|██████████| 60/60 [00:01<00:00, 34.19it/s, loss=2.3153, acc=30.76%]\n",
      "Epoch 49 Val: 100%|██████████| 12/12 [00:00<00:00, 57.69it/s, val_loss=2.2652, val_acc=32.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 49:\n",
      "Harchinov\n",
      "Betten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Train: 100%|██████████| 60/60 [00:01<00:00, 34.15it/s, loss=2.3109, acc=31.13%]\n",
      "Epoch 50 Val: 100%|██████████| 12/12 [00:00<00:00, 55.05it/s, val_loss=2.2606, val_acc=32.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 50:\n",
      "Nisem\n",
      "Davan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Train: 100%|██████████| 60/60 [00:01<00:00, 34.32it/s, loss=2.3108, acc=31.13%]\n",
      "Epoch 51 Val: 100%|██████████| 12/12 [00:00<00:00, 58.54it/s, val_loss=2.2577, val_acc=32.51%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 51:\n",
      "Saishin\n",
      "Kaner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Train: 100%|██████████| 60/60 [00:01<00:00, 33.52it/s, loss=2.3094, acc=31.29%]\n",
      "Epoch 52 Val: 100%|██████████| 12/12 [00:00<00:00, 55.04it/s, val_loss=2.2593, val_acc=32.57%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 52:\n",
      "Garleev\n",
      "Hopan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Train: 100%|██████████| 60/60 [00:01<00:00, 33.92it/s, loss=2.3050, acc=31.28%]\n",
      "Epoch 53 Val: 100%|██████████| 12/12 [00:00<00:00, 57.97it/s, val_loss=2.2560, val_acc=32.62%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 53:\n",
      "Hannouf\n",
      "Tanella\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Train: 100%|██████████| 60/60 [00:01<00:00, 33.96it/s, loss=2.3032, acc=31.37%]\n",
      "Epoch 54 Val: 100%|██████████| 12/12 [00:00<00:00, 56.34it/s, val_loss=2.2583, val_acc=32.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 54:\n",
      "Waires\n",
      "Kins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Train: 100%|██████████| 60/60 [00:01<00:00, 34.01it/s, loss=2.2969, acc=31.34%]\n",
      "Epoch 55 Val: 100%|██████████| 12/12 [00:00<00:00, 58.82it/s, val_loss=2.2569, val_acc=32.97%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 55:\n",
      "Raoshi\n",
      "Wokin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Train: 100%|██████████| 60/60 [00:01<00:00, 34.13it/s, loss=2.2992, acc=31.45%]\n",
      "Epoch 56 Val: 100%|██████████| 12/12 [00:00<00:00, 56.87it/s, val_loss=2.2532, val_acc=32.70%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 56:\n",
      "Dukin\n",
      "Awraku\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Train: 100%|██████████| 60/60 [00:01<00:00, 32.10it/s, loss=2.2998, acc=31.52%]\n",
      "Epoch 57 Val: 100%|██████████| 12/12 [00:00<00:00, 56.34it/s, val_loss=2.2505, val_acc=33.13%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 57:\n",
      "Nader\n",
      "Zhachima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Train: 100%|██████████| 60/60 [00:01<00:00, 32.22it/s, loss=2.2939, acc=31.82%]\n",
      "Epoch 58 Val: 100%|██████████| 12/12 [00:00<00:00, 57.15it/s, val_loss=2.2548, val_acc=32.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 58:\n",
      "Allour\n",
      "Bilin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 Train: 100%|██████████| 60/60 [00:01<00:00, 34.72it/s, loss=2.2915, acc=31.87%]\n",
      "Epoch 59 Val: 100%|██████████| 12/12 [00:00<00:00, 57.69it/s, val_loss=2.2516, val_acc=32.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 59:\n",
      "Cham\n",
      "Shakan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 Train: 100%|██████████| 60/60 [00:01<00:00, 32.98it/s, loss=2.2943, acc=31.70%]\n",
      "Epoch 60 Val: 100%|██████████| 12/12 [00:00<00:00, 54.55it/s, val_loss=2.2483, val_acc=33.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 60:\n",
      "Ovin\n",
      "Batis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 Train: 100%|██████████| 60/60 [00:01<00:00, 32.56it/s, loss=2.2892, acc=31.72%]\n",
      "Epoch 61 Val: 100%|██████████| 12/12 [00:00<00:00, 58.80it/s, val_loss=2.2559, val_acc=32.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 61:\n",
      "Aramord\n",
      "Allon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 Train: 100%|██████████| 60/60 [00:01<00:00, 32.35it/s, loss=2.2874, acc=31.66%]\n",
      "Epoch 62 Val: 100%|██████████| 12/12 [00:00<00:00, 57.97it/s, val_loss=2.2523, val_acc=32.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 62:\n",
      "Pilker\n",
      "Isa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 Train: 100%|██████████| 60/60 [00:01<00:00, 32.68it/s, loss=2.2878, acc=31.74%]\n",
      "Epoch 63 Val: 100%|██████████| 12/12 [00:00<00:00, 60.31it/s, val_loss=2.2486, val_acc=33.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 63:\n",
      "Taranov\n",
      "Catlen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 Train: 100%|██████████| 60/60 [00:03<00:00, 17.52it/s, loss=2.2802, acc=31.91%]\n",
      "Epoch 64 Val: 100%|██████████| 12/12 [00:00<00:00, 29.20it/s, val_loss=2.2468, val_acc=32.87%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 64:\n",
      "Warrorl\n",
      "Sheez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 Train: 100%|██████████| 60/60 [00:04<00:00, 13.83it/s, loss=2.2830, acc=32.14%]\n",
      "Epoch 65 Val: 100%|██████████| 12/12 [00:00<00:00, 57.42it/s, val_loss=2.2495, val_acc=33.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 65:\n",
      "Borrer\n",
      "Grovan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 Train: 100%|██████████| 60/60 [00:01<00:00, 34.25it/s, loss=2.2811, acc=32.05%]\n",
      "Epoch 66 Val: 100%|██████████| 12/12 [00:00<00:00, 56.46it/s, val_loss=2.2487, val_acc=32.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 66:\n",
      "Chorin\n",
      "Rous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 Train: 100%|██████████| 60/60 [00:01<00:00, 34.25it/s, loss=2.2781, acc=32.08%]\n",
      "Epoch 67 Val: 100%|██████████| 12/12 [00:00<00:00, 56.60it/s, val_loss=2.2442, val_acc=33.10%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 67:\n",
      "Roog\n",
      "Nason\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 Train: 100%|██████████| 60/60 [00:01<00:00, 33.31it/s, loss=2.2746, acc=32.13%]\n",
      "Epoch 68 Val: 100%|██████████| 12/12 [00:00<00:00, 55.81it/s, val_loss=2.2422, val_acc=33.15%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 68:\n",
      "Salldal\n",
      "Ferish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 Train: 100%|██████████| 60/60 [00:01<00:00, 32.08it/s, loss=2.2774, acc=32.15%]\n",
      "Epoch 69 Val: 100%|██████████| 12/12 [00:00<00:00, 56.60it/s, val_loss=2.2470, val_acc=32.98%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 69:\n",
      "Ansie\n",
      "Elgants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 Train: 100%|██████████| 60/60 [00:01<00:00, 33.52it/s, loss=2.2706, acc=32.27%]\n",
      "Epoch 70 Val: 100%|██████████| 12/12 [00:00<00:00, 54.79it/s, val_loss=2.2403, val_acc=33.40%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 70:\n",
      "Galaits\n",
      "Isanev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 Train: 100%|██████████| 60/60 [00:01<00:00, 32.50it/s, loss=2.2708, acc=32.30%]\n",
      "Epoch 71 Val: 100%|██████████| 12/12 [00:00<00:00, 53.57it/s, val_loss=2.2370, val_acc=33.41%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 71:\n",
      "Stald\n",
      "Roschin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 Train: 100%|██████████| 60/60 [00:01<00:00, 32.64it/s, loss=2.2717, acc=32.27%]\n",
      "Epoch 72 Val: 100%|██████████| 12/12 [00:00<00:00, 56.07it/s, val_loss=2.2434, val_acc=33.06%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 72:\n",
      "Abshinov\n",
      "Fabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 Train: 100%|██████████| 60/60 [00:01<00:00, 33.06it/s, loss=2.2712, acc=32.29%]\n",
      "Epoch 73 Val: 100%|██████████| 12/12 [00:00<00:00, 56.87it/s, val_loss=2.2422, val_acc=33.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 73:\n",
      "Ferrele\n",
      "Pealiman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 Train: 100%|██████████| 60/60 [00:01<00:00, 33.65it/s, loss=2.2682, acc=32.43%]\n",
      "Epoch 74 Val: 100%|██████████| 12/12 [00:00<00:00, 57.14it/s, val_loss=2.2427, val_acc=33.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 74:\n",
      "Hanlel\n",
      "Araman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 Train: 100%|██████████| 60/60 [00:01<00:00, 34.23it/s, loss=2.2659, acc=32.56%]\n",
      "Epoch 75 Val: 100%|██████████| 12/12 [00:00<00:00, 57.14it/s, val_loss=2.2412, val_acc=32.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples after epoch 75:\n",
      "Curuner\n",
      "Terino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 Train: 100%|██████████| 60/60 [00:01<00:00, 31.68it/s, loss=2.2607, acc=32.67%]\n",
      "Epoch 76 Val: 100%|██████████| 12/12 [00:00<00:00, 52.94it/s, val_loss=2.2411, val_acc=33.18%]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T07:45:12.896561Z",
     "start_time": "2025-04-18T07:45:12.872562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.cpu()\n",
    "final_samples = decode_samples(\n",
    "    sample_from_model(model, vectorizer, num_samples=10, temperature=0.6),\n",
    "    vectorizer\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Generated Samples:\")\n",
    "print(\"-\" * 30)\n",
    "for i, name in enumerate(final_samples):\n",
    "    print(f\"{i + 1}. {name}\")"
   ],
   "id": "aaaa9f6614b0cb84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Generated Samples:\n",
      "------------------------------\n",
      "1. Arahas\n",
      "2. Badyan\n",
      "3. Baba\n",
      "4. Catser\n",
      "5. Girmond\n",
      "6. Ficher\n",
      "7. Salid\n",
      "8. Ancham\n",
      "9. Manger\n",
      "10. Goren\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
